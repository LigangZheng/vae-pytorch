{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# plotting params\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 12\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1129fbf50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(423212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       # transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       # transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                   ])),\n",
    "                    batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Encoder\n",
    "\n",
    "We'll start with the simplest autoencoder: a single, fully-connected layer as the encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, encoding_dim)\n",
    "        self.decoder = nn.Linear(encoding_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = F.relu(self.encoder(x))\n",
    "        decoded = F.tanh(self.decoder(encoded))\n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "encoding_dim = 32\n",
    "\n",
    "model = AutoEncoder(input_dim, encoding_dim)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l1_penalty(var):\n",
    "    return torch.abs(var).sum()\n",
    "\n",
    "def train(epoch, l1_weight=1e-5):\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data.view([-1, 784]))\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        decoder_out, encoder_out = model(data)\n",
    "        mse_loss = F.mse_loss(decoder_out, data)\n",
    "        l1_reg = l1_weight * l1_penalty(encoder_out)\n",
    "        loss = mse_loss + l1_reg\n",
    "\n",
    "        # output = model(data)\n",
    "        # loss = F.mse_loss(output, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.970128\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.469364\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.303272\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.274700\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.268970\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.249156\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.255584\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.246375\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.230465\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.240516\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.232490\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.213734\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.230494\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.220564\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.207116\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.216764\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.219703\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.211262\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.220656\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.207698\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.209680\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.208933\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.219320\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.202008\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.204774\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.191986\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.204597\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.197704\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.206302\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.197890\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.209302\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.198862\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.196769\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.207706\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.197375\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.196804\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.201135\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.196631\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.190686\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.192946\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.195245\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.185926\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.194105\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.201283\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.192048\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.198466\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.194553\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.181364\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.196109\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.186861\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.195594\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.196764\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.194609\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.192295\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.185959\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.190206\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.188935\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.199999\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.187864\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.186934\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.186274\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.184814\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.189268\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.179906\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.183318\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.184496\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.184356\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.192058\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.185636\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.189991\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.185872\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.179685\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.194794\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.179165\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.184570\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.192970\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.179729\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.176115\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.183038\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.183725\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.193244\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.181691\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.181083\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.175485\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.189019\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.181912\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.177201\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.181915\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.183227\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.195286\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.177908\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.185643\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.188157\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.183434\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.182626\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.187608\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.179125\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.183992\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.184327\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.183790\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.182859\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.177301\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.171499\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.176715\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.188962\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.183523\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.178358\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.181928\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.178177\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.174918\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.180172\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.180028\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.188372\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.175564\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.190257\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.185837\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.176375\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.186968\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.187297\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.182946\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.184866\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.179465\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.178883\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.176097\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.185637\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.175142\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.182824\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.170452\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.177573\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.175754\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.169056\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.182390\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.185915\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.176115\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.181899\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.182154\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.173573\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.176915\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.181373\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.168077\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.172249\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.174033\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.182560\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.179565\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.183066\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.181235\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.185085\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.178584\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.175777\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.175253\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.178859\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.180817\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.179064\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.177126\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.173680\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.180928\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.181245\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.179006\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.182259\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.173054\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.182925\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.184788\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.174151\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.182441\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.181777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.181457\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.179232\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.184184\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.175271\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.179108\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.178627\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.182402\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.171773\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.174758\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.181951\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.180780\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.181016\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.178470\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.176105\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.178941\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.177840\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.173338\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.175136\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.177079\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.180185\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.167154\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.174210\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.177245\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.172115\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.182379\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.180128\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.179448\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.175418\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.176124\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.187351\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.169117\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.180947\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.173142\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.174367\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.171600\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.171517\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 0.181282\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.174574\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.190740\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.184057\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 0.170023\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.188545\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 0.175111\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.178959\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 0.177589\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.164043\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 0.174443\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.164985\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 0.178862\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.179172\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.177711\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.178806\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 0.176588\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.179875\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 0.170909\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.172062\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 0.176937\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.176872\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 0.188983\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.177660\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.167052\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.180309\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 0.183248\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.176840\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 0.170479\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.170007\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 0.181358\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.177115\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 0.173408\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.179660\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.174746\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.186038\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 0.173674\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.181773\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 0.176995\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.173986\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 0.168599\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.184830\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 0.174500\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.179270\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.177566\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.178574\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 0.175807\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.183023\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 0.184946\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.180107\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tLoss: 0.171477\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.173861\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 0.169166\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.180897\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 0.177375\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.175440\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tLoss: 0.174700\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.175664\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 0.172524\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.176098\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tLoss: 0.172321\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.185773\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 0.178077\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.181839\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 0.178023\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.169270\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tLoss: 0.181166\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.173667\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 0.175179\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.172835\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tLoss: 0.175507\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.170551\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 0.180975\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.170537\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 0.168625\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.173797\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tLoss: 0.174523\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.168100\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 0.171726\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.170739\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tLoss: 0.187251\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.179234\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 0.170189\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.176452\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 0.180823\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.181081\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tLoss: 0.183795\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.179017\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 0.171333\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.170550\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tLoss: 0.170939\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.174842\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 0.183562\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.178735\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 0.176093\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.184080\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tLoss: 0.174427\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.179601\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 0.172847\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(1,  num_epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode and decode the test set\n",
    "data, _ = next(iter(test_loader))\n",
    "data = Variable(data.view([-1, 784]), volatile=True)\n",
    "true_imgs = data\n",
    "encoded_imgs = F.relu(model.encoder(data))\n",
    "decoded_imgs = model.decoder(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = x.data.numpy()\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = np.clip(x, 0, 1)\n",
    "    x = x.reshape([-1, 28, 28])\n",
    "    return x\n",
    "\n",
    "true_imgs = to_img(true_imgs)\n",
    "decoded_imgs = to_img(decoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xm8XfPZ///rSIIkCIkEIQOJkEES\nMgg1JeaYNaaqW7mL3tVWJ1T5tmpoHw9Kq6pU72rNYmyMqXKHIIIgicwSMslgjoSEkPP7w8/l/bly\n9s4+J3vvs/Y+r+df18paZ5+Ps/Zn7bWXz3VdNbW1tQYAAAAAAIDGt0FjDwAAAAAAAABf4kENAAAA\nAABARvCgBgAAAAAAICN4UAMAAAAAAJARPKgBAAAAAADICB7UAAAAAAAAZETzfDtramro3d1Iamtr\na4r1WpzHxlOs88g5bDzMxerAXKx8zMXqwFysfMzF6sBcrHzMxeqQ6zyyogYAAAAAACAjeFADAAAA\nAACQETyoAQAAAAAAyAge1AAAAAAAAGQED2oAAAAAAAAyggc1AAAAAAAAGcGDGgAAAAAAgIzgQQ0A\nAAAAAEBGNG/sAaDp+PnPf+5xy5Ytk319+/b1eMSIETlf4/rrr/f4+eefT/bdeuut6ztEAAAAAAAa\nFStqAAAAAAAAMoIHNQAAAAAAABnBgxoAAAAAAICMqKmtrc29s6Ym906UVG1tbU2xXqsxz+PIkSM9\nzld7piHmzJmTbB9wwAEez58/v6i/q6GKdR6rdS726NEj2Z4xY4bH55xzjsfXXntt2cYUVctcLFTr\n1q09vvLKKz0+66yzkuNefvllj4877rhk37x580o0uoZjLla+pjYXqxVzsfIxF6sDc7F+tthiC487\nd+5c0M/E+6Gf/OQnHk+ZMsXjWbNmJcdNmjSpoNdnLlaHXOeRFTUAAAAAAAAZwYMaAAAAAACAjKA9\nN4pKU53MCk930pSXf//73x7vsMMOyXFHHHGEx926dUv2nXzyyR7/7ne/K+j3onHtuuuuyfaaNWs8\nXrhwYbmHAzPbZpttPD7jjDM81nNjZjZgwACPDz/88GTfddddV6LR4Su77babx/fff3+yr2vXriX7\nvQcddFCyPX36dI8XLFhQst+LwuhnpJnZgw8+6PEPfvADj2+44YbkuC+++KK0A6syHTp08Pjuu+/2\neNy4cclxN954o8dz584t+bi+0qZNm2R7n3328Xj06NEer169umxjAirBYYcd5vGRRx6Z7Ntvv/08\n7t69e0GvF1OaunTp4vFGG22U8+eaNWtW0OujurGiBgAAAAAAICN4UAMAAAAAAJARpD5hvQ0cONDj\nY445JudxU6dO9TguJ3z33Xc9XrFihccbbrhhctz48eM97tevX7KvXbt2BY4YWdG/f/9k++OPP/b4\ngQceKPdwmqT27dsn2zfffHMjjQT1cfDBB3ucb/l0scXUmtNPP93jE088sWzjwNf0s+8vf/lLzuP+\n/Oc/e3zTTTcl+1auXFn8gVUR7fZilt7PaJrR0qVLk+MaK91Ju/KZpdd5TVudPXt26QdWgTbbbLNk\nW9Pp+/Tp47F2GzUjlSzLtFzC2Wef7bGmeJuZtWzZ0uOamvVvqBS7mwL1wYoaAAAAAACAjOBBDQAA\nAAAAQEbwoAYAAAAAACAjylqjJrZq1rzARYsWJftWrVrl8e233+7xkiVLkuPIr2182s435nNqHrfW\nVFi8eHFBr/2zn/0s2e7Vq1fOYx955JGCXhONS/O7tV2smdmtt95a7uE0ST/60Y88Pvroo5N9gwcP\nrvfraetXM7MNNvj6/wFMmjTJ47Fjx9b7tfG15s2//sgePnx4o4wh1r746U9/6nHr1q2TfVpzCqWj\n82+77bbLedydd97psd5joW5bbrmlxyNHjkz2tW3b1mOtC/TDH/6w9APL4aKLLvJ4++23T/adddZZ\nHnPfXLeTTz7Z48svvzzZ16lTpzp/Jtayee+994o/MBSFXhvPOeeckv6uGTNmeKzfg1Bc2iJdr9dm\nac1UbatuZrZmzRqPb7jhBo+fe+655LgsXCtZUQMAAAAAAJARPKgBAAAAAADIiLKmPl1xxRXJdteu\nXQv6OV2yuXz58mRfOZeULVy40OP43zJhwoSyjSNrHnroIY91GZpZer7ef//9er92bPfaokWLer8G\nsmXnnXf2OKZKxOXlKI0//OEPHusS0IY69thjc27PmzfP4xNOOCE5LqbRIL+hQ4d6vMcee3gcP49K\nKbYp1nTUVq1aJftIfSqN2I79wgsvLOjnNLW0tra2qGOqRrvttpvHcem8uuSSS8owmrX17t072dZU\n8QceeCDZx2dr3TQd5o9//KPH2vLeLPd8ufbaa5NtTeduyD0v1i2muGgak6aujB49Ojnu008/9XjZ\nsmUex88pvS99/PHHk31Tpkzx+IUXXvD41VdfTY5buXJlztdH/Wi5BLN0jum9ZnxfFGr33Xf3+PPP\nP0/2zZw50+Nnn3022afvu88++6xBv7sQrKgBAAAAAADICB7UAAAAAAAAZAQPagAAAAAAADKirDVq\ntB23mVnfvn09nj59erKvZ8+eHufLEx4yZIjHCxYs8DhXK726aE7aO++847G2nY7mz5+fbDflGjVK\n61E01Lnnnutxjx49ch6n+aF1bSObzjvvPI/j+4V5VDqPPvqox9o+u6G0DemKFSuSfV26dPFY28S+\n+OKLyXHNmjVb73FUs5ibre2V58yZ4/Fvf/vbso3pqKOOKtvvQt122WWXZHvAgAE5j9X7m8cee6xk\nY6oGHTp0SLa/+c1v5jz2v//7vz3W+8ZS07o0TzzxRM7jYo2aWN8RX/r5z3/usbZcL1Ssu3bIIYd4\nHFt8az2bUta0qEb56sb069fPY23JHI0fP95j/V45d+7c5LjOnTt7rLVJzYpT0w9102cCZ599tsdx\njm222WZ1/vxbb72VbD/zzDMev/nmm8k+/R6itRIHDx6cHKfXhOHDhyf7Jk2a5LG2+C42VtQAAAAA\nAABkBA9qAAAAAAAAMqKsqU9PPvlk3m0V26p9JbYG7d+/v8e6fGnQoEEFj2vVqlUez5o1y+OYjqVL\noHTZOdbf4Ycf7rG2utxwww2T495++22PL7jggmTfJ598UqLRYX107do12R44cKDHOt/MaGNYTPvu\nu2+yvdNOO3msy3cLXcobl3bq8mNtdWlmNmzYMI/ztQ7+n//5H4+vv/76gsbRlFx00UXJti7/1iX2\nMfWs2PSzL76vWApefvlScqKYJoDcrrrqqmT729/+tsd6f2lmds8995RlTNHee+/t8VZbbZXs++c/\n/+nxbbfdVq4hVRRNyzUzO+200+o8bvLkycn20qVLPT7ggANyvn6bNm081rQqM7Pbb7/d4yVLlqx7\nsE1YvPe/4447PNZUJ7M09TdfOqCK6U4qlrZAafz1r39NtjVtLV+rbX128Nprr3n8y1/+MjlOv9tH\ne+65p8d6H3rTTTclx+kzBr0GmJldd911Ht93330eFzsVlhU1AAAAAAAAGcGDGgAAAAAAgIwoa+pT\nMXzwwQfJ9pgxY+o8Ll9aVT66pDimWekSq5EjRzbo9VE3TYeJSx6V/t2ffvrpko4JxRFTJVQ5u2U0\nBZpmdtdddyX78i0lVdqJS5dz/uY3v0mOy5dqqK9x5plnety+ffvkuCuuuMLjjTfeONn35z//2ePV\nq1eva9hVY8SIER7HLgOzZ8/2uJwd0jR9LaY6PfXUUx5/+OGH5RpSk7bPPvvk3Be7yeRLPUSqtrY2\n2db3+qJFi5J9peza07Jly2Rbl/R///vf9ziO9/TTTy/ZmKqFpjKYmW266aYea5eYeN+in08nnXSS\nxzHdolu3bh5vvfXWyb5Ro0Z5fOihh3r8/vvvFzT2arfJJpt4HEsbaHmEd999N9n3+9//3mNKIGRL\nvK/Tbkvf/e53k301NTUe63eDmBZ/5ZVXetzQcgnt2rXzWLuPXnzxxclxWoYlpk2WCytqAAAAAAAA\nMoIHNQAAAAAAABnBgxoAAAAAAICMqLgaNaXQoUMHj//yl794vMEG6XMsbRtNTun6+de//pVsH3TQ\nQXUed8sttyTbsV0tsm+XXXbJuU9rlGD9NW/+9SW90Jo0sdbTiSee6HHMBS+U1qj53e9+5/HVV1+d\nHNeqVSuP43vhwQcf9HjOnDkNGkclOu644zzWv49Z+vlUalrv6OSTT/b4iy++SI677LLLPG5KtYTK\nTduJahzFnP2JEyeWbExNyWGHHZZsa9tzrc0U6ykUSmui7Lfffsm+IUOG1Pkz9957b4N+V1O20UYb\nJdta5+cPf/hDzp/TVr//+Mc/PNbrtZnZDjvskPM1tH5KKWscVaqjjz7a41/84hfJPm2ZrS3qzcyW\nLVtW2oGhweK17Nxzz/VYa9KYmb311lsea73YF198sUG/W2vPdOrUKdmn3y0fffRRj2NtWhXHe+ut\nt3pcyvp8rKgBAAAAAADICB7UAAAAAAAAZASpT2Z29tlne6ztY2Mr8JkzZ5ZtTNVom2228Tgu3dbl\nqJpuocvqzcxWrFhRotGhmHSp9mmnnZbse/XVVz3+z3/+U7Yx4Wva2jm2dG1oulMumsKkKTRmZoMG\nDSrq76pEbdq0SbZzpTmYNTytoiG0rbqm0U2fPj05bsyYMWUbU1NW6Fwp53uk2lxzzTXJ9tChQz3u\n2LFjsk9bpOuS+COPPLJBv1tfI7bdVm+88YbHsTU01k1ba0ea3hbT83MZOHBgwb97/PjxHnMvu7Z8\nKZ1637hw4cJyDAdFoOlHZmunTqvPP//c4913393jESNGJMftvPPOdf78ypUrk+2ePXvWGZul97lb\nbbVVzjGppUuXJtvlSvtmRQ0AAAAAAEBG8KAGAAAAAAAgI5pk6tM3vvGNZDtWF/+KViA3M5syZUrJ\nxtQU3HfffR63a9cu53G33Xabx02p20s1OeCAAzxu27Ztsm/06NEeaycFFFfsWqd0WWmp6ZL+OKZ8\nY7z44os9PuWUU4o+rqyIXUi23XZbj++8885yD8d169atzn/nc7Bx5EuxKEbXIZi9/PLLyXbfvn09\n7t+/f7LvkEMO8Vg7mbzzzjvJcTfffHNBv1s7iEyaNCnncePGjfOY+6P6i9dUTVXT9MKYXqHdK485\n5hiPY5cYnYtx3xlnnOGxnu9p06YVNPZqF1NclM63X//618m+UaNGeUyXu2z5v//7v2RbU6X1e4KZ\nWefOnT3+05/+5HG+VFBNpYppVvnkSndas2ZNsv3AAw94/KMf/SjZt3jx4oJ/3/pgRQ0AAAAAAEBG\n8KAGAAAAAAAgI3hQAwAAAAAAkBE1+XK/ampqcu+sYJdffnmyfcEFF3j85JNPejx8+PDkuFK234pq\na2tr1n1UYRrzPGr+79133+1xixYtkuOeeuopj4866iiPK72FYbHOY6XNxXvuucfjb37zm8k+3db8\nz6yqpLn4+9//3uNzzjkn53Fx/pXSD3/4Q4+vvvrqZJ/WqIm5wVojoBi1GLI6F1u2bJlsP/PMMx7H\n86Ttgt9///1iDsM6dOiQbOfKv4552tddd11Rx5FPJc3FYthrr708fvrppz2OtZ3mzZvncdeuXUs+\nrvWV1bnYmHbYYQePZ8+enezTuhsHH3ywx7EeTjlV6lyMNfP0b92mTRsdU3Jcru9KTzzxRLJ99tln\ne/zwww8n+3bccUeP//a3v3n8ve99b13DLpkszUX9G8f7gXz02BtuuMFjbYdultZA0fM+derUnK/d\nu3fvZPv555/3OCttwit1Lm6++ebJttaL1Vqy7733XnLc/PnzPdYaf/369UuOGzx4cL3HpO8fM7Nf\n/vKXHmv9qVLIdR5ZUQMAAAAAAJARPKgBAAAAAADIiCbTnluXl2ubNzOzzz77zGNt+1bOVKdqEdtu\n67KxfOkWurS30tOdmqqtt97a47333tvjmTNnJsdVQrpTpTriiCMa5fe2b98+2e7Vq5fHeg3IJy7j\nbyrX35UrVybbmuYV0wYfeeQRj2MaWSH69OmTbGu6RUyZybXUvz5L0rF+9PM0Xyv7//znP+UYDkro\nV7/6lcdx7p1//vkeN2a6UzWIKaPHH3+8x/fee6/HmgYVXXvttR7ruTEzW7Vqlcf3339/sk9TOzSF\nrVu3bslxTbXtuqZu//SnPy345/Ta+P3vf7/OuFh0/mnJhhNPPLHov6vaxVQinR8NccsttyTb+VKf\nli9f7rG+1/75z38mx2n778bCihoAAAAAAICM4EENAAAAAABARvCgBgAAAAAAICOaTI2ac8891+Nd\nd9012Td69GiPx40bV7YxVaOf/exnyfagQYPqPO5f//pXsq21gVCZvvOd73isrX4fe+yxRhgNyunC\nCy9MtrVFaT5z5871+NRTT032aQvGpkSvhbFF7GGHHebxnXfeWe/Xfvfdd5NtrYWx5ZZbFvQaMYcb\npTNixIg6/z3m9v/1r38tx3BQRMcdd1yy/V//9V8ea/0Es7Xb06J4tL22zrdvfetbyXE657SekNak\niS699NJku2fPnh4feeSRdb6e2dqfhU2F1igZOXJksu+OO+7wuHnz9Ktrp06dPM5Xy6sYtB6fvl8u\nuuii5LjLLruspOPAl8477zyP61Mn6Hvf+57HDbmXKidW1AAAAAAAAGQED2oAAAAAAAAyompTn3SJ\nuJnZ//t//8/jjz76KNl3ySWXlGVMTUGhLfV+8IMfJNu05K58Xbp0qfPfP/jggzKPBOXw6KOPerzT\nTjs16DWmTZvm8bPPPrveY6oGM2bM8Fhbx5qZ9e/f3+Pu3bvX+7W1/Wx08803J9snn3xyncfFduIo\nnu222y7ZjukXX1m4cGGyPWHChJKNCaVx6KGH5tz38MMPJ9uvvPJKqYcDS9OgNG6oeK3UdB5NfRo6\ndGhyXNu2bT2O7cSrmbZCjte0Hj165Py5/fff3+MWLVp4fPHFFyfH5SrF0FCamjxgwICivjZy++53\nv+uxppzFlDg1derUZPv+++8v/sBKhBU1AAAAAAAAGcGDGgAAAAAAgIyoqtSndu3aefynP/0p2des\nWTOPdcm+mdn48eNLOzCsRZd2mpmtXr263q+xbNmynK+hyx/btGmT8zU233zzZLvQ1C1donn++ecn\n+z755JOCXqPaHH744XX++0MPPVTmkTRduhQ3X/eDfMvub7zxRo87duyY8zh9/TVr1hQ6xMQRRxzR\noJ9rqiZOnFhnXAxvvPFGQcf16dMn2Z4yZUpRx9GU7bnnnsl2rjkcuyai8sRr8Mcff+zxVVddVe7h\noAzuvvtujzX16YQTTkiO09IAlGZYtyeffLLOf9dUYbM09enzzz/3+B//+Edy3N/+9jePf/zjHyf7\ncqWjonQGDx6cbOv1cZNNNsn5c1pSQ7s8mZl9+umnRRpd6bGiBgAAAAAAICN4UAMAAAAAAJARPKgB\nAAAAAADIiIqvUaO1Z0aPHu3x9ttvnxw3Z84cj7VVNxrH5MmT1/s17rnnnmR78eLFHm+11VYex/zf\nYluyZEmyffnll5f092XFXnvtlWxvvfXWjTQSfOX666/3+Iorrsh5nLZ/zVdfptDaM4Ued8MNNxR0\nHMpP6xvVtf0VatKUjtbZi959912Pr7nmmnIMB0WmdRL0HsXM7O233/aYdtzVST8n9fP5qKOOSo77\n9a9/7fFdd92V7Js1a1aJRld9Hn/88WRb7821lfMZZ5yRHNe9e3eP99tvv4J+18KFCxswQhQi1jLc\ndNNN6zxO63yZpXWgnnvuueIPrExYUQMAAAAAAJARPKgBAAAAAADIiIpPferWrZvHAwYMyHmctl3W\nNCgUV2x9Hpd0FtNxxx3XoJ/Ttnz5UjYefPBBjydMmJDzuGeeeaZB46h0xxxzTLKtaYivvvqqx2PH\nji3bmJq6+++/3+Nzzz032de+ffuS/d533nkn2Z4+fbrHZ555pseanohsqa2tzbuN0jv44INz7ps/\nf77Hy5YtK8dwUGSa+hTn1yOPPJLz53Sp/xZbbOGxvidQWSZOnOjxr371q2TflVde6fFvf/vbZN8p\np5zi8cqVK0s0uuqg9yFmaXv0448/PufPDR06NOe+L774wmOds7/4xS8aMkTkoNe88847r6Cfuf32\n25Ptp556qphDajSsqAEAAAAAAMgIHtQAAAAAAABkBA9qAAAAAAAAMqLiatR06dIl2Y7t174S6zNo\nO1qUzrHHHptsa25hixYtCnqN3r17e1yf1to33XSTx3Pnzs153H333efxjBkzCn59mLVq1crj4cOH\n5zzu3nvv9VhzelFa8+bN8/jEE09M9h199NEen3POOUX9vbEl/XXXXVfU10fpbbzxxjn3UQuhdPRz\nUWvuRatWrfJ49erVJR0Tyk8/J08++eRk309+8hOPp06d6vGpp55a+oGh5G655ZZk+6yzzvI43lNf\ncsklHk+ePLm0A6tw8XPrxz/+scebbLKJxwMHDkyO69Chg8fxu8Stt97q8cUXX1yEUeIrek6mTZvm\ncb7vjjoH9PxWE1bUAAAAAAAAZAQPagAAAAAAADKiJl8Lzpqamsz154xL7C+44II6jxs8eHCyna+9\nchbV1tbWFOu1sngem4pincesnENdgvj0008n+95++22Pv/Wtb3n8ySeflH5gJVSNc/GQQw7xWNtn\nm5kdccQRHmuL+htvvDE5rqbm6z+LLlM1y2bb2Gqbi8W2ZMmSZLt5868zoy+99FKPr7nmmrKNKarG\nudisWTOP//d//zfZ953vfMdjTY+o9JSXpjoXtSXzLrvskuzT62m8L//73//usc7FBQsWFHuIBavG\nuZgVnTt39jim3tx5550exxS5hmiqc1Fpy3MzsyFDhnj8m9/8Jtmn97lZUS1z8cgjj/R41KhRHud7\nTrH//vt7PGbMmNIMrExynUdW1AAAAAAAAGQED2oAAAAAAAAyoiJSn/baay+PH3300WSfVolWpD59\nLSvnsSliWWnlYy5WB+Zifg899FCyffXVV3uclSXF1T4XO3bsmGxfdtllHr/88sseV3pXtaY6F/Ve\nVrv3mJmNHTvW4+uvvz7Z98EHH3j82WeflWh09VPtczErYmfbPfbYw+Pdd9/d45h+XKimOherSbXM\nxUmTJnkcU0PVlVde6fH5559f0jGVE6lPAAAAAAAAGceDGgAAAAAAgIzgQQ0AAAAAAEBGNF/3IY1v\n77339jhXTRozszlz5ni8YsWKko4JAIBqoW3Z0TgWLVqUbJ9++umNNBKUwrPPPuvxsGHDGnEkqBQj\nRoxItrWOR/fu3T1uaI0aICvatm3rcU3N1+VaYkv0P/7xj2UbUxawogYAAAAAACAjeFADAAAAAACQ\nERWR+pSPLgPcf//9PX7//fcbYzgAAAAAsF4++uijZHv77bdvpJEApXX11VfXGV966aXJcYsXLy7b\nmLKAFTUAAAAAAAAZwYMaAAAAAACAjOBBDQAAAAAAQEbU1NbW5t5ZU5N7J0qqtra2Zt1HFYbz2HiK\ndR45h42HuVgdmIuVj7lYHZiLlY+5WB2Yi5WPuVgdcp1HVtQAAAAAAABkBA9qAAAAAAAAMiJv6hMA\nAAAAAADKhxU1AAAAAAAAGcGDGgAAAAAAgIzgQQ0AAAAAAEBG8KAGAAAAAAAgI3hQAwAAAAAAkBE8\nqAEAAAAAAMgIHtQAAAAAAABkBA9qAAAAAAAAMoIHNQAAAAAAABnBgxoAAAAAAICM4EENAAAAAABA\nRvCgBgAAAAAAICN4UAMAAAAAAJARPKgBAAAAAADICB7UAAAAAAAAZAQPagAAAAAAADKCBzUAAAAA\nAAAZwYMaAAAAAACAjOBBDQAAAAAAQEbwoAYAAAAAACAjeFADAAAAAACQETyoAQAAAAAAyAge1AAA\nAAAAAGRE83w7a2pqass1EKRqa2trivVanMfGU6zzyDlsPMzF6sBcrHzMxerAXKx8zMXqwFysfMzF\n6pDrPLKiBgAAAAAAICN4UAMAAAAAAJARPKgBAAAAAADICB7UAAAAAAAAZAQPagAAAAAAADKCBzUA\nAAAAAAAZwYMaAAAAAACAjOBBDQAAAAAAQEbwoAYAAAAAACAjmjf2AAAzsw4dOnjcsmVLj1u0aJEc\n9/HHH3u8ePHi0g8MAAAAAIAyYkUNAAAAAABARvCgBgAAAAAAICN4UAMAAAAAAJAR1KhBUfXp0yfZ\nHjhwoMc9evTwuGvXrslxW2yxhcdal2b16tXJcStXrvT4o48+SvZpzZpZs2Z5PHny5OS4l19+Oef4\nAdRf69atk+1Vq1Z5/MUXX5R7OAAAAEBFY0UNAAAAAABARvCgBgAAAAAAICNIfcJ6+8Y3vuHxnnvu\nmezr37+/xzvuuKPH2223XXLc5ptv7vHGG2/scU1NTXJcbW2tx9qq28xs0aJFHr/44ose52vxPWPG\nDEN5bbXVVh63b98+2ff55597vGDBAo/juUZ5dO/e3WOdv2Zm7dq187hZs2bJPk1RfOeddzzW9EQz\ns4ULF3q8YsWK9Rss0ER169bNY72+RkuXLvV47ty5yT5SFAE0RR07dky2W7Zs6fGyZcuSfe+++25Z\nxgR8hRU1AAAAAAAAGcGDGgAAAAAAgIwg9Qn11qpVq2R7s802y7lvzZo1Hn/44Ycex25OutRQO8jE\n19PjPv3002Sfvr7u0zGYrZ2mgdKKS/E1HU7fO2bpstLly5d7TOpT6fTu3TvZHjp0qMc77bSTx1tu\nuWVynM6jOMc0RfGTTz7xWFMvzMzeeOMNj6dMmZLs023SovKLqaRdunTxeJNNNvE4prdoWtqcOXOS\nffzNs0uvoXFbOyiapd0RNQ34gw8+SI57//33izlE/P+026Vea+Pnot4TxbQ07VSp9zkonR122CHZ\n7ty5s8f6WbjRRhslx+m9yuuvv57smzp1ajGHiHWI9/qDBg3yWNO64zVTxVSnN99802PtKKv3Ocie\neL3Veyb9HhLvkfS8ajdTs/QeSdP643fT9cWKGgAAAAAAgIzgQQ0AAAAAAEBG8KAGAAAAAAAgI6qq\nRs0+++zjcay7oDmlMc9McxDffvttj2M9hZkzZ3qs9TOampiLqW2xp02blnNf8+Zfv91iTYsNN9zQ\nY23VHds3ay5pzD/VnHvNI9WeGCieAAAa30lEQVQWwGZmb731lqF8evXqlWxrPYWY3z1v3jyPdS5y\nzorrpJNO8viAAw5I9mnutta0yNemMtac0roomtsfW3zvvPPOHm+99dbJvg02+Pr/I4wbN66O/4qm\nZ+DAgR7rPNK/sZnZxhtv7LHmS8c6JEuWLPG4bdu2yT493++9957HOkdRPnp+tt9++2Sfziude2Zp\n7rx+HuvcRv21adPG4yOPPNLjIUOGJMfp3NSae59//nlynN5XxfpBBx10kMdaS+rFF19Mjps4cWJB\nY2/K9D7UzGy33XbzWNvcx8+jTTfd1GOdO/o5ZZZeb2PtMP1sfe211zzWWm1YP7vvvrvHWpPGLK3d\npt8zIp2LsTbftttu63HPnj09jnWldG5SY7G4+vXr5/GBBx7ocadOnZLjtKZpnPd6/rV+Taybqd/1\nYx0/Pccav/DCC/n/A+qJFTUAAAAAAAAZwYMaAAAAAACAjKiI1CdNadJlTnGfLnPTJU9RXLo9a9Ys\njzXdSVMvzMxmzJjhsbZli9srV67M+burkS7h1GXWZumyUE2PiKlPulRf053iUjZdSqpLj83S5Yqa\n7qRpUGa0tywHbeu89957J/s0fSMu/9bWeJpqiPqLre2//e1ve3zIIYd4vMsuuyTHaRqipkrE9DO9\nbsZ0SF0urOlNseWppmzEtoi6lHjSpEkeV/syYv3baat0s3Tu6N8ynmtdrqstuOPfTpcDx6X+uky8\npqbG4/i5qJ99CxYsMJSGfhbqnDJL51FMxdD23JouTPv1+jniiCNybg8ePNjjjh07JsfpvY6ei3gf\nonNMr8Fm6T2Rpr3FOaufp1OmTKnjv6Jp0r+TXkPN0rmjKRAxNVDvX2tra3P+Lv3uoddQM7NtttnG\nY32fPPPMM8lxnLv8dK6Ypfcze+yxh8ddu3ZNjtP0NX0NnZdm6eenfjcxM2vdurXHej47dOiQHKdz\n+Kmnnkr2Fbt9czXSFNILL7ww2Xf44YcX9Bqasj179uxkn85hvQa0a9cu5+vF76N6DS/lnGVFDQAA\nAAAAQEbwoAYAAAAAACAjeFADAAAAAACQEZmpURPzeo899liPtTWh5h+ard06LRetoRBz7LUVoual\naj6jWdoaOrYy1by22A662mkOdvzbNoTWTdCcYbM0/z7mCWueqbadnT9//nqPCfWjrYNji0TNEdfz\nZJa2F411T1A/Rx11VLJ98MEHe6wtLGM7Qq0zonW5xowZkxyndWPiXNQ2p5rjHa/XWmcqfgZoXQZt\n415tNWr0c8Usremk58nMrG/fvh7r305zsc3SujSam63n0yxtsR5z7LWVrJ43PS9m6TU5npvYDhwN\np/Uu9NyYmfXo0cNjra9gltaS0vNTbfOoGGLL3r322svj4cOHJ/t0nmrdmFh/4vXXX/dY665p/S+z\ntAZKnItaC0PnYmz/rDU5mnKdk1hfRv9O8TNI29lrnbRly5Ylx2k9ilWrVuX83fp5qu+L+Lu1lk28\nD2rK564QWhPKLK2zp+2zY+22zz77zGP9zIyttXVfvD/Sekd6vYh1c/R+RsdkRjv2XPS7/lVXXeVx\nnz59Cvr5+P3z8ccf9zjWz9NrrJ7TfDVqtMabWVqPNtZwLCZW1AAAAAAAAGQED2oAAAAAAAAyIjOp\nT3Fpky7l1RSk2Fr7lVde8ViXPekyUrN02VNcoqRt1GL7WKWpNXFZJK0u148u69bWzv369UuO69y5\ns8easmaWLhfVltxNrV16Y9Fl17rUWOeyWbrMMC4B1eXgsZ0e1k2XBMfWzpqCpkt24xL81157zePx\n48d7/MQTTyTHLV26NOc4NKVG3xfxuqxpMzHVVJccxzbu1SS2cNW/V/w80pRbTSuKKU16DqdPn+6x\nphaapUv4Y9taTa/R9KyYqqWpNjF9jdSn9aPvDV2qramFZmnb0Dlz5iT7dLl/vjmLtVub6zUppiNp\nWoWmrujcMzN74YUXPNY0qLhMX18vpnZoyoyOKbbx1rTxpix+zmjaUrxX1/tITX3Kl06q6W3xPZPr\nXtYsPY/5PvuwNk0tim3pNV1F/6563s3S+xL9jjB16tTkOH2PaOtms7Q9t6YBawqdWZryHd8jqNsJ\nJ5zgcaHpTg899JDHd9xxR7JP26LH86PlVQ444ICCflcso6HPHzTFuNh49wAAAAAAAGQED2oAAAAA\nAAAyIjPrJLUCulm6JFu7i8TUJ013Wbx4sce63NssXdIYq77vueeeHmvKRuw6o+lTuoTVbO0ldsgv\npjTp8sJevXp5rOfGLF1OGFMxNI2GJd7lp/NKUzTiMlVdlhzn6YQJEzym69O6xU4D2hUvdgzSziG6\nVD+mSug50etrfeaUnmPtwBGv8zr+uGxfO0lVW/qi/nfHVCKdL7G7oKax6NLtmG7x0ksveVxoB5GY\nEqCpZ5paEzt8aUpAHC/Wj74X9N5k5513To7T95CmaJul90zTpk0r9hCrSkzV05SFmL6gx2rXmOef\nfz45TtNHdel87DSj51fvgczSFCftgBc7TMWUfHxJr1ExpSnX3zN2YtJurnodjh2gNMUifj5r2oz+\nXEzVwto0PSx+zmjaoJ5DPe9maYqwfi7qd8wofl/U94uOI18XvThP8SXtqmeWpvTqPI3lSh577DGP\nb7vtNo/z3evENFG9p4np50rvi+K1feTIkTl/rphYUQMAAAAAAJARPKgBAAAAAADICB7UAAAAAAAA\nZESj1qjR2gWR1pvRXLXYXnTy5Mn1/r3NmjVLtrfaaiuPNY9Na9KYmc2cOdPjmPuIddO865iDrfnZ\n2tIw5uJrnYyYG8w5KS/NC450HsXcUM31jm0RGzKfm7JY60nr0sTWztriWlvDxvxf3Y71a3KJ9WV0\nHFp/Ktao0dxtzfs3S/P2qy2HXz/7tLVo3NaaXGZpDQqtoRA/qxpSi2T77bdPtvv27euxXq9jPTat\nlaM1GFB/sZ5XmzZtPN5222091nsWs3RuL1q0KNkX6xehcFqXJt5v6PzTOkDxeqotgfO1q9f7nnjt\n1vsjPdexHpG2msbX9LoZa9/p31PjeL71b63Hxba/eh2N9U10Put1VGtoom4dOnTwOP5d9b5Ca8XE\nOkNafy/fvabW8+vevXuyb5dddvFYz3Vs3azfM6vt/qVY9G9plv6dtM6exmZmo0aN8rjQGnzDhg1L\ntg899NCCfu6FF17w+IEHHkj2xXp9pcKKGgAAAAAAgIzgQQ0AAAAAAEBGNGrqk7Y5i8sRdfmuLiWN\nLQ0bIqbdxPSaun6vmdns2bPX+3c3ZbpcW8+9WdrGUNvwxXQIXdob2wXrclSUXlzOuXz5co81ZSOm\npOkS0diee82aNcUcYtUbOHBgsq3XtrgkW5cBa+qTLs03S5d4x/mXy5577plsDx061GNtgxiXeGvr\nw7jUPF+7y0qXq8WnWdpqOaY+6fVP50r8u2oqWr5zqMu699tvv2TfkCFDPG7fvr3H8TzpEu+YAof6\niWnZuq2pT5HeP2kqmhn3LetD3+vxeqT3LHpcTPXVNApNF958882T47RV7YABA5J9mmKh5zOOKd5H\nY22xZbaeE01J1ftQszQtcbPNNvO4f//+yXH77LOPxz169Ej26bVdv+PkKwOBL3Xs2NFjTYMyS1Nu\ndQ7Ezyr9nNTXiOd6jz328HjfffdN9g0ePNhj/bzTch1madqkxk2d/q3jedTUUP1+F1PwNZUxn65d\nu3p85plnJvu0FbiKv+uhhx7yeOzYsQX93mLj3QMAAAAAAJARPKgBAAAAAADIiEZdp6zL3mOakS6/\n165PDU1v0SXeuqTbLF3SqBWkWTK8/nRpoC7TjWlLepwuf4vnQM8PaTONK6Y+xWWmX4mpT9qhhjlW\nf3q9immbusw+zgedV3pOYheffEuHc4nLSHUcutRc0+PM0iXB+nkQx1httEtF7JSkS/HjPl06r+8D\n7axlli7x1s/P2C1DU+f233//ZF/nzp091s/jfO8X7eKF+su3pFvfC7HbhKYvzpgxI9kXzxcKp/cp\nMUVUaYpa7MiVqxNanIuaQtOzZ89kn6axrly50uM437gHWreYnqkpaHoeY1dLTWPSDl277bZbcpxe\ni/V6bZZeK3UOx9+l5zt+LjZV2g0xzh39O2uqb0yt0S6Zet60q5pZmkIe07r13kbTyeP9cEyxw5e0\no11MCdN7Ff0sjCngen60k1o8bsSIER4fc8wxOcekJVXuvvvuZN+9996b8+fKhRU1AAAAAAAAGcGD\nGgAAAAAAgIzgQQ0AAAAAAEBGZKaX5rRp05JtbV+q+faF1qiJuW977723x9p6zSzNAdXWlloPBQ2j\n50vzvWNuteYGa90SrWdiZjZu3DiP4/nRnF9tCRxzxjVHWXNMzYrT/r2p0pzc2GZWaRtD6ifUn+ZT\n53tva10Rs7RGjeYCa5tQM7NJkyZ5XGi715hjr9dsfY34vtBWttoy3GztuV+tYmttrTMR6ynkqk8U\n8+E1Z1/rDMWaCX369PFYWwCbpddunbOxDanmksf3HOon1qPQnHtt4Rtr1Ohn5rx580o0uqZn5syZ\nHsc6XDpP89U20eM0jm28tVaK1igxS98Xeu2O7xetz4G6xb+R1hBq3769x/E7RNu2bT3u27evx7E+\nmH53ifQzTq+b8XtNfG80RfGzT89TnGN6bvK1Otf6Mvp62267bXKcbsc6N3o/o99p9P7KLH2faX3O\npk6vlfnqEOrfL14P9b5XPyPjXDz++OMLGtMTTzzh8ahRo5J9sX5uY2BFDQAAAAAAQEbwoAYAAAAA\nACAjMpP6FK1vm8+4BGrYsGEed+3aNdmny55IdyodbV+nLSbN0taX2nY7pl48++yzHsfWwbmWMsb3\ngi6ji6lPuo/3Qv3o31zTc3RJt1l6rmnnW3+xBaHS+RKX2+p7fdasWR6PGTMmOW7+/PkFjUOXeMfU\nG52butR1s802S47TVICY6lTN80/nQEw906W2uqTbLE1d0hbf8e+q23qetJVlPC6mBGiKk44pLlfW\ndKe4/Bv1E5ftd+zY0WNNe4tpGXPmzPFYU2OwfjS14YUXXkj2adqufsbF+xKdO5riommHZmaDBg3y\nePny5ck+nYt6HY9zMQvL9LMutlnX86ipMdoO2iydf5oiFT/79PXi/Y1+xuk8jeebltxrt7XXVKj4\nWaXzStPGNt100+Q4vd/QffE4fY14Lj744AOPdS7GtF/d1jS3pk6vqZMnT0726f2J3rfE861zTO+J\nhgwZkhynn5+RllvR75XxOp8FrKgBAAAAAADICB7UAAAAAAAAZAQPagAAAAAAADIiszVq1tfw4cOT\n7d13393j2BJ46tSpHldzXYRyiO1ftaWl7tNcUbO0fs3ChQs9jjnYMZdXaQ6xtprt3bt3cpzmvsb6\nKZr7r7mptO1eW6yT0KtXL4+1LlA815qvSzvR+tPrV6yxpDUK4nVOa89oHahCa9JEWusr5nhrPrnW\n1IltFvPlK1dz63adE08//XSyT3OzY70RrY2gdb7i9UnPqebbxxbDWscotkfXvH/Nt4/1xTRnv6m0\nVC+V2CJdW7Br/Yw4N7TOUTXPm8akNQ3itt5TFNqKt1OnTsm2fhZqTRqzdD7rvjjfvvjii4J+d1P2\nxhtvJNuvvPKKx9r2PrZszlV3LdZS0XOg97Vm6bnTel7xOs990drzSGsLaU0us/Rvrvelen9hlt57\naovneA71niXf/au+J2Jtqnhvhi/pPWoxamqddtppHu+3334F/9xLL73k8YQJE9Z7HKXEihoAAAAA\nAICM4EENAAAAAABARlRV6pO2Gj3wwAOTfbrM7Zlnnkn2vfzyy6UdWJWJbSU15SimPmmb5i233NJj\nXS5vli5lnDdvnsdxOaGKS4d79uzpcb9+/Tzu27dvztfQFrdm6TJHXY5K6tPadthhh2RbU5+0zV5c\npqpLWlmqXX/6vtS5YpbOidgaVNMI49L6hthjjz087ty5c7JPW5vqNUGXlpuZvfbaax4//vjj6z2m\nShTTO0eOHOlxTG3Qa60uq4/nU9M2u3Tp4nGcb7odU5r0Wqi/K6afaipBfA3Uj54rs7S9qKZDzJw5\nMzkuX5tYlF6h6U6qVatWybbOt5iyoedX57qm7aNhxo0b57Gex3h/o3NTj4vp83pPGdPDNW1Gr6Mx\n7RRp6q1Zeq+gqUlm6eddvtRhbaWuacSRnrc4jtiO/SvxczymcqM0hg0b5nFMrVeaOmeWpj5l/TrK\nihoAAAAAAICM4EENAAAAAABARlRV6tNJJ53k8U477ZTs005CL774YrJv4sSJpR1YFdAK+LGLUvfu\n3T2Oywk19alDhw4ea8V7s3S5Yj76GrGDiaZkDRgwwGNNFzBLl5zG1CpNn8u1xBFf6t+/f7KtXYB0\naXCs7N6QZeL4mqY2xOW22vGlRYsWyT59P2saYkyjyGXEiBHJ9qBBgzzWeW6WXgd0mbIuMzcze/TR\nRz3Ol+bYlOhS67Fjxyb79Jqn6YWRXvM0faZt27bJcdoRKnYo0dS5fB3wJk2alHMcWDedl5qiHWmK\nWexApKkTdIzJLk1NjV2FtJOQzjez9DNTl/DT4au4Zs+e7XH8/NS0Cr32xq5Amgql59QsPa+a/q9d\n21A3TfOO6WZ6j6Hd8eL3Ed2nHfb0e4VZmr4WPxf1+qr3X9o9LO5DcQ0dOtTjWOYkl9GjRyfbjz32\nWFHHVEqsqAEAAAAAAMgIHtQAAAAAAABkBA9qAAAAAAAAMqKqatRojZJYA2X8+PEe0467/rRdXfPm\n6dtG8+p33XXXZF+u1t3aptBs7VbCX9GaMWZpS8vYylRrpuiYYr635njH94nWMtKaAPiS1n6K7dH1\nPTJ//nyPY00LbZkYWx9i3bReQWzrqe91rRlkluZna32Z2Fpbz6POX61FZZbWPtHYLM3n19ztBx98\nMDmO+ib1o63uNa8+nhu9/mldmnjt1npdsXW3XpP192qb1Hgc6k/bAGttBLP0c1LrZ+S7psbziOwY\nPHiwx/G6q/VMYn08vSZTz6R09LNVa8iYpZ+tWk8t1jDRfbF+jb6G3nvG34X84n2D3m9oXZo4x7Qu\njX4fifTcxNp5WnPxueee8/iJJ55Y17BRJMOHD/c4X123p556yuO77ror2VdJ3+9YUQMAAAAAAJAR\nPKgBAAAAAADIiIpPfTrssMM8bt26tcdTpkxJjtPl9xMmTCj9wKrMkiVLPF66dGmyT5dnx5aGuuxe\nl/bGlBdNadIl/TH1SffFttu6BPWll17yOKaH6Pjjf4u+T7QdYFOm51SXksYWibpcVJfmx/bPLN0u\nnlmzZiXb2r65Xbt2yT5d9qupSrGdry6711QZXV5sln/JqS4Jvv/++z2OLRLRcHpdi9dTPW+6/D4u\n49Yl99qq2yxNp9Gl5rE1NOpP2/vuvPPOHsc293peNS03XkNjKjGyY9999/VY07M1FdUsvbeJ6YQ6\nFxcsWFDsIaIO8e+sc1PT5+M9r6Ye1tbWJvv0PlrTw7F+9H5DP/v0OmuWnqvFixd7HD8/9XMyfn/Q\n0hkPP/xwA0eM+jjllFOSbU3d18/FmJb997//3eNHHnmkRKMrPVbUAAAAAAAAZAQPagAAAAAAADKC\nBzUAAAAAAAAZUXE1anr06JFsa66atjCM+aWvvvpqaQdW5XLVfzFLc0Jja1Ct86Jt82JLw48++shj\nrZER25Vqe8Pnn38+2TdjxgyPtfWa5gWbpXVp4jiwNq0TpHMs5u5++OGHHmv+7/Tp05PjtM0s1o+2\nijRbe06o3XbbzeNevXp5HGvZaE0TnZcam6X1nGJu8LPPPuux5nSjNLQ+lJnZ2LFj6zwu1vXadttt\nPY71wFauXOmxXsdjTSOs28Ybb5xs9+zZ02Ntzx1rKujnk9bF0JolcR8aV6zlpTWIdtxxR487deqU\nHKfvkVi/5M033/SYGjXlEa9zTz/9tMd6D6nn1yytPRTbc8+ZM8djreOH4tHzFO+H9Pujzrd4nrRG\nVPz+EK+9KI1TTz3V4xEjRiT79J5Va87ecccdyXH33XdfiUZXXqyoAQAAAAAAyAge1AAAAAAAAGRE\nRaQ+aSvZQw89NNmnLWe1vaimYZixXK2YYitQbbkbl9xrO2dtP7nRRhslx+lSQ41jKpWmPr3++uvJ\nvngsikOXAOuS39jqd/ny5R5r6pPGKK2pU6d6/PHHHyf7dMm8pirFdBhNb9Prpi6/N0uXcWvaodna\n7S6RDXEZt17LNTU1immOqJ+YDqPb2sI3prDpNVXTHGM6aTyvaDybbrppsq33pfnOtX6eTps2Ldk3\na9asOl8DjUM/72Jao96HavqoWZrSFr+joPhi+tqUKVMaaSSoS/fu3ZPtYcOGeTx06FCPY5qoXjsn\nTpzo8b///e9iDzETWFEDAAAAAACQETyoAQAAAAAAyIiafMsoa2pqGm2N5ZZbbunx4Ycf7vE+++yT\nHKfL9jUtY8yYMclxt9xyS7GHWFK1tbU16z6qMI15Hpu6Yp1HzmHjqca52KJFC48333zzZJ92cdMl\nppqSWImYi5WvGueippzp3DOr3rTRap6L8Xp64IEHeqzd9lq3bp0c984773isHfXMzJ588sliDrEo\nqnEuFoN2pImpN5rKmBXVPBebikqai7179/Z4//33T/bttddeHmtnxFatWiXHadr9vffe6/GNN95Y\ntHE2hlznkRU1AAAAAAAAGcGDGgAAAAAAgIzgQQ0AAAAAAEBGZLY9t+b5brPNNnX+e6T5n1qvBgDw\ntdWrV3ustREAlBfzr7rEtsujRo3yeOrUqR5vsEH6/0nnzp3r8YoVK0ozOJTce++919hDADKrQ4cO\nHm+33XbJvs6dO3ustZ4++uij5LglS5Z4rNfNasWKGgAAAAAAgIzgQQ0AAAAAAEBGZLY9dy5XXHFF\nsv388897rK0tn3vuueS4RYsWlXZgRVZJ7daQG60PKx9zsTowFysfc7E6MBcrH3OxOjAXK1+1z8UL\nLrgg2X7jjTc8HjlyZLmHUzK05wYAAAAAAMg4HtQAAAAAAABkBA9qAAAAAAAAMqLiatQ0FdWec9hU\nkP9b+ZiL1YG5WPmYi9WBuVj5mIvVgblY+ZiL1YEaNQAAAAAAABnHgxoAAAAAAICMyJv6BAAAAAAA\ngPJhRQ0AAAAAAEBG8KAGAAAAAAAgI3hQAwAAAAAAkBE8qAEAAAAAAMgIHtQAAAAAAABkBA9qAAAA\nAAAAMuL/A/MVugvVG/fIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117ed1748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(true_imgs[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig('./plots/simple_l1_regularization_tanh.png', format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
